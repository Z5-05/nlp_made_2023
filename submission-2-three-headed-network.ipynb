{"metadata":{"accelerator":"GPU","colab":{"name":"CNN_for_texts.ipynb","provenance":[],"version":"0.3.2"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"4c94360af41bc5f236574d890e2f9e552afa19720a4da9aea16fd5faf3da5eb4"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Homework02: Three headed network in PyTorch\n\nThis notebook accompanies the [week02](https://github.com/girafe-ai/natural-language-processing/tree/master/week02_cnn_for_texts) practice session. Refer to that notebook for more comments.\n\nAll the preprocessing is the same as in the classwork. *Including the data leakage in the train test split (it's still for bonus points).*","metadata":{"colab_type":"text","id":"13pL--6rycN3"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n\nimport nltk\nimport tqdm\nfrom collections import Counter","metadata":{"colab":{},"colab_type":"code","id":"P8zS7m-gycN5","execution":{"iopub.status.busy":"2023-03-03T17:21:57.509801Z","iopub.execute_input":"2023-03-03T17:21:57.510169Z","iopub.status.idle":"2023-03-03T17:21:58.943507Z","shell.execute_reply.started":"2023-03-03T17:21:57.510131Z","shell.execute_reply":"2023-03-03T17:21:58.942291Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"If you have already downloaded the data on the Seminar, simply run through the next cells. Otherwise uncomment the next cell (and comment the another one ;)","metadata":{}},{"cell_type":"code","source":"# uncomment and run this cell, if you don't have data locally yet.\n\n#!curl -L \"https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=1\" -o Train_rev1.csv.tar.gz\n#!tar -xvzf ./Train_rev1.csv.tar.gz\n\n# data = pd.read_csv(\"./Train_rev1.csv\", index_col=None)\n\n#!wget https://raw.githubusercontent.com/girafe-ai/natural-language-processing/22f_msai/homeworks/assignment02_three_headed_network/network.py","metadata":{"execution":{"iopub.status.busy":"2023-03-03T17:21:58.950444Z","iopub.execute_input":"2023-03-03T17:21:58.953003Z","iopub.status.idle":"2023-03-03T17:21:58.959600Z","shell.execute_reply.started":"2023-03-03T17:21:58.952940Z","shell.execute_reply":"2023-03-03T17:21:58.958264Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# run this cell if you have downloaded the dataset on the seminar\ndata = pd.read_csv(\"../input/train-dataset/rev1.csv\", index_col=None)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"colab_type":"code","id":"vwN72gd4ycOA","outputId":"7b9e8549-3128-4041-c4be-33fb6f326c78","execution":{"iopub.status.busy":"2023-03-03T17:21:58.964591Z","iopub.execute_input":"2023-03-03T17:21:58.965558Z","iopub.status.idle":"2023-03-03T17:22:09.222154Z","shell.execute_reply.started":"2023-03-03T17:21:58.965257Z","shell.execute_reply":"2023-03-03T17:22:09.221114Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data[\"Log1pSalary\"] = np.log1p(data[\"SalaryNormalized\"]).astype(\"float32\")\ntext_columns = [\"Title\", \"FullDescription\"]\ncategorical_columns = [\n    \"Category\",\n    \"Company\",\n    \"LocationNormalized\",\n    \"ContractType\",\n    \"ContractTime\",\n]\ntarget_column = \"Log1pSalary\"\n\ndata[categorical_columns] = data[categorical_columns].fillna(\n    \"NaN\"\n)  # cast missing values to string \"NaN\"\n\ndata.sample(3)\n\n\ndata_for_autotest = data[-5000:]\ndata = data[:-5000]","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"colab_type":"code","id":"UuuKIKfrycOH","outputId":"e5de0f94-a4f6-4b51-db80-9d11ddc1db31","execution":{"iopub.status.busy":"2023-03-03T17:22:09.224619Z","iopub.execute_input":"2023-03-03T17:22:09.224909Z","iopub.status.idle":"2023-03-03T17:22:09.345833Z","shell.execute_reply.started":"2023-03-03T17:22:09.224882Z","shell.execute_reply":"2023-03-03T17:22:09.344811Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"tokenizer = nltk.tokenize.WordPunctTokenizer()\n# see task above\ndef normalize(text):\n    text = str(text).lower()\n    return \" \".join(tokenizer.tokenize(text))\n\n\ndata[text_columns] = data[text_columns].applymap(normalize)\n\nprint(\"Tokenized:\")\nprint(data[\"FullDescription\"][2::100000])\nassert (\n    data[\"FullDescription\"][2][:50]\n    == \"mathematical modeller / simulation analyst / opera\"\n)\nassert data[\"Title\"][54321] == \"international digital account manager ( german )\"\n\n# Count how many times does each token occur in both \"Title\" and \"FullDescription\" in total\n# build a dictionary { token -> it's count }\nfrom collections import Counter\nfrom tqdm import tqdm as tqdm\n\ntoken_counts = Counter()  # <YOUR CODE HERE>\nfor _, row in tqdm(data[text_columns].iterrows()):\n    for string in row:\n        token_counts.update(string.split())\n\n# hint: you may or may not want to use collections.Counter","metadata":{"colab":{},"colab_type":"code","id":"RUWkpd7PycOQ","execution":{"iopub.status.busy":"2023-03-03T17:22:09.348126Z","iopub.execute_input":"2023-03-03T17:22:09.348848Z","iopub.status.idle":"2023-03-03T17:22:56.370441Z","shell.execute_reply.started":"2023-03-03T17:22:09.348804Z","shell.execute_reply":"2023-03-03T17:22:56.369282Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Tokenized:\n2         mathematical modeller / simulation analyst / o...\n100002    a successful and high achieving specialist sch...\n200002    web designer html , css , javascript , photosh...\nName: FullDescription, dtype: object\n","output_type":"stream"},{"name":"stderr","text":"239768it [00:26, 9004.41it/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"token_counts.most_common(1)[0][1]","metadata":{"execution":{"iopub.status.busy":"2023-03-03T17:22:56.372089Z","iopub.execute_input":"2023-03-03T17:22:56.372992Z","iopub.status.idle":"2023-03-03T17:22:56.410140Z","shell.execute_reply.started":"2023-03-03T17:22:56.372947Z","shell.execute_reply":"2023-03-03T17:22:56.409117Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"2598827"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Total unique tokens :\", len(token_counts))\nprint(\"\\n\".join(map(str, token_counts.most_common(n=5))))\nprint(\"...\")\nprint(\"\\n\".join(map(str, token_counts.most_common()[-3:])))\n\nassert token_counts.most_common(1)[0][1] in range(2500000, 2700000)\nassert len(token_counts) in range(200000, 210000)\nprint(\"Correct!\")\n\nmin_count = 10\n\n# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\ntokens = [\n    token for token, count in token_counts.items() if count >= min_count\n]  # <YOUR CODE HERE>\n# Add a special tokens for unknown and empty words\nUNK, PAD = \"UNK\", \"PAD\"\ntokens = [UNK, PAD] + sorted(tokens)\nprint(\"Vocabulary size:\", len(tokens))\n\nassert type(tokens) == list\nassert len(tokens) in range(32000, 35000)\nassert \"me\" in tokens\nassert UNK in tokens\nprint(\"Correct!\")\n\ntoken_to_id = {token: idx for idx, token in enumerate(tokens)}\nassert isinstance(token_to_id, dict)\nassert len(token_to_id) == len(tokens)\nfor tok in tokens:\n    assert tokens[token_to_id[tok]] == tok\n\nprint(\"Correct!\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":215},"colab_type":"code","id":"GiOWbc15ycOb","outputId":"1e807140-5513-4af0-d9a9-9f029059a553","execution":{"iopub.status.busy":"2023-03-03T17:22:56.411829Z","iopub.execute_input":"2023-03-03T17:22:56.412231Z","iopub.status.idle":"2023-03-03T17:22:56.618119Z","shell.execute_reply.started":"2023-03-03T17:22:56.412194Z","shell.execute_reply":"2023-03-03T17:22:56.615887Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Total unique tokens : 201127\n('and', 2598827)\n('.', 2471477)\n(',', 2266256)\n('the', 2036428)\n('to', 1977039)\n...\n('dbms_stats', 1)\n('dbms_output', 1)\n('dbms_job', 1)\nCorrect!\nVocabulary size: 33795\nCorrect!\nCorrect!\n","output_type":"stream"}]},{"cell_type":"code","source":"UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n\n\ndef as_matrix(sequences, max_len=None):\n    \"\"\"Convert a list of tokens into a matrix with padding\"\"\"\n    if isinstance(sequences[0], str):\n        sequences = list(map(str.split, sequences))\n\n    max_len = min(max(map(len, sequences)), max_len or float(\"inf\"))\n\n    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n    for i, seq in enumerate(sequences):\n        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n        matrix[i, : len(row_ix)] = row_ix\n\n    return matrix","metadata":{"colab":{},"colab_type":"code","id":"JEsLeBjVycOw","execution":{"iopub.status.busy":"2023-03-03T17:22:56.619499Z","iopub.execute_input":"2023-03-03T17:22:56.619878Z","iopub.status.idle":"2023-03-03T17:22:56.628052Z","shell.execute_reply.started":"2023-03-03T17:22:56.619829Z","shell.execute_reply":"2023-03-03T17:22:56.626873Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"data[\"Title\"][::100000]","metadata":{"execution":{"iopub.status.busy":"2023-03-03T17:22:56.630116Z","iopub.execute_input":"2023-03-03T17:22:56.630584Z","iopub.status.idle":"2023-03-03T17:22:56.645204Z","shell.execute_reply.started":"2023-03-03T17:22:56.630535Z","shell.execute_reply":"2023-03-03T17:22:56.644114Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"0         engineering systems analyst\n100000                   hr assistant\n200000         senior ec & i engineer\nName: Title, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Lines:\")\nprint(\"\\n\".join(data[\"Title\"][::100000].values), end=\"\\n\\n\")\nprint(\"Matrix:\")\nprint(as_matrix(data[\"Title\"][::100000]))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":179},"colab_type":"code","id":"JiBlPkdKycOy","outputId":"3866b444-1e2d-4d79-d429-fecc6d8e02a8","execution":{"iopub.status.busy":"2023-03-03T17:22:56.650295Z","iopub.execute_input":"2023-03-03T17:22:56.650570Z","iopub.status.idle":"2023-03-03T17:22:56.658488Z","shell.execute_reply.started":"2023-03-03T17:22:56.650544Z","shell.execute_reply":"2023-03-03T17:22:56.657257Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Lines:\nengineering systems analyst\nhr assistant\nsenior ec & i engineer\n\nMatrix:\n[[10705 29830  2143     1     1]\n [14875  2817     1     1     1]\n [27345 10107    15 15069 10702]]\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.feature_extraction import DictVectorizer\n\n# we only consider top-1k most frequent companies to minimize memory usage\ntop_companies, top_counts = zip(*Counter(data[\"Company\"]).most_common(1000))\nrecognized_companies = set(top_companies)\ndata[\"Company\"] = data[\"Company\"].apply(\n    lambda comp: comp if comp in recognized_companies else \"Other\"\n)\n\ncategorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\ncategorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"colab_type":"code","id":"DpOlBp7ZycO6","outputId":"30a911f2-7d35-4cb5-8991-60457b1e8bac","execution":{"iopub.status.busy":"2023-03-03T17:22:56.660275Z","iopub.execute_input":"2023-03-03T17:22:56.660849Z","iopub.status.idle":"2023-03-03T17:23:03.877460Z","shell.execute_reply.started":"2023-03-03T17:22:56.660803Z","shell.execute_reply":"2023-03-03T17:23:03.876469Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"DictVectorizer(dtype=<class 'numpy.float32'>, sparse=False)"},"metadata":{}}]},{"cell_type":"markdown","source":"### The deep learning part\n\nOnce we've learned to tokenize the data, let's design a machine learning experiment.\n\nAs before, we won't focus too much on validation, opting for a simple train-test split.\n\n__To be completely rigorous,__ we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes.\n\n\n#### Here comes the simple one-headed network from the seminar. ","metadata":{"colab_type":"text","id":"yk4jmtAYycO8"}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndata_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\ndata_train.index = range(len(data_train))\ndata_val.index = range(len(data_val))\n\nprint(\"Train size = \", len(data_train))\nprint(\"Validation size = \", len(data_val))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"colab_type":"code","id":"TngLcWA0ycO_","outputId":"6731b28c-07b1-41dc-9574-f76b01785bba","execution":{"iopub.status.busy":"2023-03-03T17:23:03.878965Z","iopub.execute_input":"2023-03-03T17:23:03.879343Z","iopub.status.idle":"2023-03-03T17:23:04.025658Z","shell.execute_reply.started":"2023-03-03T17:23:03.879304Z","shell.execute_reply":"2023-03-03T17:23:04.024417Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Train size =  191814\nValidation size =  47954\n","output_type":"stream"}]},{"cell_type":"code","source":"def make_batch(data, max_len=None, word_dropout=0):\n    \"\"\"\n    Creates a keras-friendly dict from the batch data.\n    :param word_dropout: replaces token index with UNK_IX with this probability\n    :returns: a dict with {'title' : int64[batch, title_max_len]\n    \"\"\"\n    batch = {}\n    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n    batch[\"Categorical\"] = categorical_vectorizer.transform(\n        data[categorical_columns].apply(dict, axis=1)\n    )\n\n    if word_dropout != 0:\n        batch[\"FullDescription\"] = apply_word_dropout(\n            batch[\"FullDescription\"], 1.0 - word_dropout\n        )\n\n    if target_column in data.columns:\n        batch[target_column] = data[target_column].values\n\n    return batch\n\n\ndef apply_word_dropout(\n    matrix,\n    keep_prop,\n    replace_with=UNK_IX,\n    pad_ix=PAD_IX,\n):\n    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n    dropout_mask &= matrix != pad_ix\n    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])","metadata":{"colab":{},"colab_type":"code","id":"2PXuKgOSycPB","execution":{"iopub.status.busy":"2023-03-03T17:23:04.027452Z","iopub.execute_input":"2023-03-03T17:23:04.027836Z","iopub.status.idle":"2023-03-03T17:23:04.037531Z","shell.execute_reply.started":"2023-03-03T17:23:04.027796Z","shell.execute_reply":"2023-03-03T17:23:04.036380Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"a = make_batch(data_train[:3], max_len=10)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":251},"colab_type":"code","id":"I6LpEQf0ycPD","outputId":"e3520cae-fba1-46cc-a216-56287b6e4929","execution":{"iopub.status.busy":"2023-03-03T17:23:04.039194Z","iopub.execute_input":"2023-03-03T17:23:04.040035Z","iopub.status.idle":"2023-03-03T17:23:04.053461Z","shell.execute_reply.started":"2023-03-03T17:23:04.039996Z","shell.execute_reply":"2023-03-03T17:23:04.052408Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"But to start with let's build the simple model using only the part of the data. Let's create the baseline solution using only the description part (so it should definetely fit into the Sequential model).","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2023-03-03T17:23:04.055038Z","iopub.execute_input":"2023-03-03T17:23:04.055456Z","iopub.status.idle":"2023-03-03T17:23:06.169878Z","shell.execute_reply.started":"2023-03-03T17:23:04.055415Z","shell.execute_reply":"2023-03-03T17:23:06.168752Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-03-03T17:23:06.171495Z","iopub.execute_input":"2023-03-03T17:23:06.172107Z","iopub.status.idle":"2023-03-03T17:23:06.235307Z","shell.execute_reply.started":"2023-03-03T17:23:06.172044Z","shell.execute_reply":"2023-03-03T17:23:06.234141Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"# You will need these to make it simple\n\n\nclass Flatten(nn.Module):\n    def forward(self, input):\n        return input.view(input.size(0), -1)\n\n\nclass Reorder(nn.Module):\n    def forward(self, input):\n        return input.permute((0, 2, 1))","metadata":{"execution":{"iopub.status.busy":"2023-03-03T17:23:06.236905Z","iopub.execute_input":"2023-03-03T17:23:06.237642Z","iopub.status.idle":"2023-03-03T17:23:06.244655Z","shell.execute_reply.started":"2023-03-03T17:23:06.237604Z","shell.execute_reply":"2023-03-03T17:23:06.243562Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"To generate minibatches we will use simple pyton generator.","metadata":{}},{"cell_type":"code","source":"def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, **kwargs):\n    \"\"\"iterates minibatches of data in random order\"\"\"\n    while True:\n        indices = np.arange(len(data))\n        if shuffle:\n            indices = np.random.permutation(indices)\n\n        for start in range(0, len(indices), batch_size):\n            batch = make_batch(data.iloc[indices[start : start + batch_size]], **kwargs)\n            target = batch.pop(target_column)\n            yield batch, target\n\n        if not cycle:\n            break","metadata":{"execution":{"iopub.status.busy":"2023-03-03T17:23:06.246172Z","iopub.execute_input":"2023-03-03T17:23:06.246906Z","iopub.status.idle":"2023-03-03T17:23:06.255169Z","shell.execute_reply.started":"2023-03-03T17:23:06.246836Z","shell.execute_reply":"2023-03-03T17:23:06.253999Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"iterator = iterate_minibatches(data_train, 3)\nbatch, target = next(iterator)","metadata":{"execution":{"iopub.status.busy":"2023-03-03T17:23:06.256969Z","iopub.execute_input":"2023-03-03T17:23:06.257601Z","iopub.status.idle":"2023-03-03T17:23:06.274769Z","shell.execute_reply.started":"2023-03-03T17:23:06.257564Z","shell.execute_reply":"2023-03-03T17:23:06.273823Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Here is some startup code:\nn_tokens = len(tokens)\nn_cat_features = len(categorical_vectorizer.vocabulary_)\nhid_size = 64\nsimple_model = nn.Sequential()\n\nsimple_model.add_module(\n    \"emb\", nn.Embedding(num_embeddings=n_tokens, embedding_dim=hid_size)\n)\nsimple_model.add_module(\"reorder\", Reorder())\nsimple_model.add_module(\n    \"conv1\", nn.Conv1d(in_channels=hid_size, out_channels=hid_size, kernel_size=2)\n)\nsimple_model.add_module(\"relu1\", nn.ReLU())\nsimple_model.add_module(\"adapt_avg_pool\", nn.AdaptiveAvgPool1d(output_size=1))\nsimple_model.add_module(\"flatten1\", Flatten())\nsimple_model.add_module(\"linear1\", nn.Linear(in_features=hid_size, out_features=1))\n# <YOUR CODE HERE>","metadata":{"execution":{"iopub.status.busy":"2023-03-03T17:23:06.277200Z","iopub.execute_input":"2023-03-03T17:23:06.277795Z","iopub.status.idle":"2023-03-03T17:23:06.324780Z","shell.execute_reply.started":"2023-03-03T17:23:06.277758Z","shell.execute_reply":"2023-03-03T17:23:06.323790Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"__Remember!__ We are working with regression problem and predicting only one number.","metadata":{}},{"cell_type":"code","source":"# Try this to check your model. `torch.long` tensors are required for nn.Embedding layers.\nsimple_model(torch.tensor(batch[\"FullDescription\"], dtype=torch.long))","metadata":{"execution":{"iopub.status.busy":"2023-03-03T17:23:06.328584Z","iopub.execute_input":"2023-03-03T17:23:06.328894Z","iopub.status.idle":"2023-03-03T17:23:06.479177Z","shell.execute_reply.started":"2023-03-03T17:23:06.328867Z","shell.execute_reply":"2023-03-03T17:23:06.477985Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"tensor([[-0.1187],\n        [-0.0067],\n        [-0.1845]], grad_fn=<AddmmBackward0>)"},"metadata":{}}]},{"cell_type":"markdown","source":"And now simple training pipeline (it's commented because we've already done that in class. No need to do it again).","metadata":{}},{"cell_type":"code","source":"# from IPython.display import clear_output\n# from random import sample\n\n# epochs = 1\n\n# model = simple_model\n# opt = torch.optim.Adam(model.parameters())\n# loss_func = nn.MSELoss()\n\n# history = []\n# for epoch_num in range(epochs):\n#     for idx, (batch, target) in enumerate(iterate_minibatches(data_train)):\n#         # Preprocessing the batch data and target\n#         batch = torch.tensor(batch['FullDescription'], dtype=torch.long)\n\n#         target = torch.tensor(target)\n\n\n#         predictions = model(batch)\n#         predictions = predictions.view(predictions.size(0))\n\n#         loss = loss_func(predictions, target)# <YOUR CODE HERE>\n\n#         # train with backprop\n#         loss.backward()\n#         opt.step()\n#         opt.zero_grad()\n#         # <YOUR CODE HERE>\n\n#         history.append(loss.data.numpy())\n#         if (idx+1)%10==0:\n#             clear_output(True)\n#             plt.plot(history,label='loss')\n#             plt.legend()\n#             plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-03T17:23:06.480884Z","iopub.execute_input":"2023-03-03T17:23:06.481657Z","iopub.status.idle":"2023-03-03T17:23:06.489264Z","shell.execute_reply.started":"2023-03-03T17:23:06.481616Z","shell.execute_reply":"2023-03-03T17:23:06.488263Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"### Actual homework starts here\n__Your ultimate task is to code the three headed network described on the picture below.__ \nTo make it closer to the real world, please store the network code in file `network.py` in this directory. ","metadata":{}},{"cell_type":"markdown","source":"#### Architecture\n\nOur main model consists of three branches:\n* Title encoder\n* Description encoder\n* Categorical features encoder\n\nWe will then feed all 3 branches into one common network that predicts salary.\n\n<img src=\"https://github.com/yandexdataschool/nlp_course/raw/master/resources/w2_conv_arch.png\" width=600px>\n\nThis clearly doesn't fit into PyTorch __Sequential__ interface. To build such a network, one will have to use [__PyTorch nn.Module API__](https://pytorch.org/docs/stable/nn.html#torch.nn.Module).","metadata":{"colab_type":"text","id":"0eI5h9UMycPF"}},{"cell_type":"code","source":"# import network","metadata":{"execution":{"iopub.status.busy":"2023-03-03T17:23:06.492938Z","iopub.execute_input":"2023-03-03T17:23:06.493906Z","iopub.status.idle":"2023-03-03T17:23:06.500467Z","shell.execute_reply.started":"2023-03-03T17:23:06.493864Z","shell.execute_reply":"2023-03-03T17:23:06.499438Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Re-run this cell if you updated the file with network source code\n# import imp\n# imp.reload(network)","metadata":{"execution":{"iopub.status.busy":"2023-03-03T17:23:06.502122Z","iopub.execute_input":"2023-03-03T17:23:06.502605Z","iopub.status.idle":"2023-03-03T17:23:06.510227Z","shell.execute_reply.started":"2023-03-03T17:23:06.502569Z","shell.execute_reply":"2023-03-03T17:23:06.509033Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"class ThreeInputsNet(nn.Module):\n    def __init__(\n        self, n_tokens, n_cat_features, concat_number_of_features, hid_size=64\n    ):\n        super(ThreeInputsNet, self).__init__()\n        self.title_emb = nn.Embedding(n_tokens, embedding_dim=hid_size)\n        self.title_net = nn.Sequential(\n            nn.Conv1d(in_channels=hid_size, out_channels=hid_size, kernel_size=2),\n            nn.ReLU(),\n            nn.AdaptiveAvgPool1d(output_size=1),\n            nn.Flatten(),\n            nn.Linear(hid_size, concat_number_of_features),\n        )\n\n        self.full_emb = nn.Embedding(num_embeddings=n_tokens, embedding_dim=hid_size)\n        self.full_net = nn.Sequential(\n            nn.Conv1d(in_channels=hid_size, out_channels=hid_size, kernel_size=2),\n            nn.ReLU(),\n            nn.AdaptiveAvgPool1d(output_size=1),\n            nn.Flatten(),\n            nn.Linear(hid_size, concat_number_of_features),\n        )\n\n        self.category_out = nn.Sequential(\n            nn.Linear(n_cat_features, hid_size),\n            nn.ReLU(),\n            nn.Linear(hid_size, concat_number_of_features),\n        )\n\n        # Example for the final layers (after the concatenation)\n        self.inter_dense = nn.Linear(\n            in_features=3 * concat_number_of_features, out_features=hid_size * 2\n        )\n        self.final_dense = nn.Linear(in_features=hid_size * 2, out_features=1)\n\n    def forward(self, whole_input):\n        input1, input2, input3 = whole_input\n        title_beg = self.title_emb(input1).permute((0, 2, 1))\n        title = self.title_net(title_beg)\n\n        full_beg = self.full_emb(input2).permute((0, 2, 1))\n        full = self.full_net(full_beg)\n\n        category = self.category_out(input3)\n\n        concatenated = torch.cat(\n            [\n                title.view(title.size(0), -1),\n                full.view(full.size(0), -1),\n                category.view(category.size(0), -1),\n            ],\n            dim=1,\n        )\n\n        out = self.final_dense(F.relu(self.inter_dense(concatenated)))\n\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-03-03T17:23:06.512171Z","iopub.execute_input":"2023-03-03T17:23:06.512975Z","iopub.status.idle":"2023-03-03T17:23:06.526565Z","shell.execute_reply.started":"2023-03-03T17:23:06.512895Z","shell.execute_reply":"2023-03-03T17:23:06.525051Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# model = network.ThreeInputsNet(\nmodel = ThreeInputsNet(\n    n_tokens=len(tokens),\n    n_cat_features=len(categorical_vectorizer.vocabulary_),\n    # this parameter defines the number of the inputs in the layer,\n    # which stands after the concatenation. In should be found out by you.\n    concat_number_of_features=128,\n)\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-03-03T17:23:06.529334Z","iopub.execute_input":"2023-03-03T17:23:06.529636Z","iopub.status.idle":"2023-03-03T17:23:08.935021Z","shell.execute_reply.started":"2023-03-03T17:23:06.529608Z","shell.execute_reply":"2023-03-03T17:23:08.933932Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"testing_batch, _ = next(iterate_minibatches(data_train, 3))\ntesting_batch = [\n    torch.tensor(testing_batch[\"Title\"], dtype=torch.long).to(device),\n    torch.tensor(testing_batch[\"FullDescription\"], dtype=torch.long).to(device),\n    torch.tensor(testing_batch[\"Categorical\"]).to(device),\n]","metadata":{"execution":{"iopub.status.busy":"2023-03-03T17:23:08.936712Z","iopub.execute_input":"2023-03-03T17:23:08.937117Z","iopub.status.idle":"2023-03-03T17:23:08.953273Z","shell.execute_reply.started":"2023-03-03T17:23:08.937077Z","shell.execute_reply":"2023-03-03T17:23:08.952302Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"assert model(testing_batch).shape == torch.Size([3, 1])\nassert model(testing_batch).dtype == torch.float32\nprint(\"Seems fine!\")","metadata":{"execution":{"iopub.status.busy":"2023-03-03T17:23:08.957708Z","iopub.execute_input":"2023-03-03T17:23:08.958187Z","iopub.status.idle":"2023-03-03T17:23:12.805245Z","shell.execute_reply.started":"2023-03-03T17:23:08.958148Z","shell.execute_reply":"2023-03-03T17:23:12.804098Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Seems fine!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Now train the network for a while (100 batches would be fine).","metadata":{}},{"cell_type":"code","source":"# Training pipeline comes here (almost the same as for the simple_model)\nfrom IPython.display import clear_output\nfrom random import sample\n\nepochs = 3\n\nopt = torch.optim.Adam(model.parameters())\nloss_func = nn.MSELoss()\n\nhistory = []\nfor epoch_num in range(epochs):\n    model.train()\n    for idx, (batch, target) in enumerate(iterate_minibatches(data_train)):\n        # Preprocessing the batch data and target\n        batch = [\n            torch.tensor(batch[\"Title\"], dtype=torch.long).to(device),\n            torch.tensor(batch[\"FullDescription\"], dtype=torch.long).to(device),\n            torch.tensor(batch[\"Categorical\"]).to(device),\n        ]\n        target = torch.tensor(target).to(device)\n        predictions = model(batch)\n        predictions = predictions.view(predictions.size(0))\n\n        loss = loss_func(predictions, target)\n\n        # train with backprop\n        loss.backward()\n        opt.step()\n        opt.zero_grad()\n        # <YOUR CODE HERE>\n        history.append(loss.data.cpu().numpy())\n        if (idx + 1) % 10 == 0:\n            clear_output(True)\n            plt.plot(history, label=\"loss\")\n            plt.legend()\n            plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-03T17:23:12.807092Z","iopub.execute_input":"2023-03-03T17:23:12.807739Z","iopub.status.idle":"2023-03-03T17:26:06.396428Z","shell.execute_reply.started":"2023-03-03T17:23:12.807699Z","shell.execute_reply":"2023-03-03T17:26:06.395425Z"},"trusted":true},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":"Now, to evaluate the model it can be switched to `eval` state.","metadata":{}},{"cell_type":"code","source":"def generate_submission(\n    model, data, batch_size=256, name=\"\", three_inputs_mode=True, **kw\n):\n    squared_error = abs_error = num_samples = 0.0\n    output_list = []\n    for batch_x, batch_y in tqdm(\n        iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw)\n    ):\n        if three_inputs_mode:\n            batch = [\n                torch.tensor(batch_x[\"Title\"], dtype=torch.long).to(device),\n                torch.tensor(batch_x[\"FullDescription\"], dtype=torch.long).to(device),\n                torch.tensor(batch_x[\"Categorical\"]).to(device),\n            ]\n        else:\n            batch = torch.tensor(batch_x[\"FullDescription\"], dtype=torch.long)\n\n        batch_pred = model(batch)[:, 0].detach().cpu().numpy()\n\n        output_list.append((list(batch_pred), list(batch_y)))\n\n        squared_error += np.sum(np.square(batch_pred - batch_y))\n        abs_error += np.sum(np.abs(batch_pred - batch_y))\n        num_samples += len(batch_y)\n    print(\"%s results:\" % (name or \"\"))\n    print(\"Mean square error: %.5f\" % (squared_error / num_samples))\n    print(\"Mean absolute error: %.5f\" % (abs_error / num_samples))\n\n    batch_pred = [c for x in output_list for c in x[0]]\n    batch_y = [c for x in output_list for c in x[1]]\n    output_df = pd.DataFrame(\n        list(zip(batch_pred, batch_y)), columns=[\"batch_pred\", \"batch_y\"]\n    )\n    output_df.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-03-03T17:26:06.400985Z","iopub.execute_input":"2023-03-03T17:26:06.403608Z","iopub.status.idle":"2023-03-03T17:26:06.417735Z","shell.execute_reply.started":"2023-03-03T17:26:06.403570Z","shell.execute_reply":"2023-03-03T17:26:06.416791Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"model.eval()\ngenerate_submission(model, data_for_autotest, name=\"Submission\")\nprint(\"Submission file generated\")","metadata":{"execution":{"iopub.status.busy":"2023-03-03T17:26:06.419150Z","iopub.execute_input":"2023-03-03T17:26:06.419850Z","iopub.status.idle":"2023-03-03T17:26:07.309241Z","shell.execute_reply.started":"2023-03-03T17:26:06.419813Z","shell.execute_reply":"2023-03-03T17:26:07.308001Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"20it [00:00, 23.58it/s]","output_type":"stream"},{"name":"stdout","text":"Submission results:\nMean square error: 0.16775\nMean absolute error: 0.32410\nSubmission file generated\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"__Both the notebook and the `.py` file are required to submit this homework.__","metadata":{}}]}